{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d5eeaf89ff30992",
   "metadata": {},
   "source": [
    "# Projet 8 ¬∑ Segmentation s√©mantique Cityscapes\n",
    "\n",
    "Ce carnet sert de journal de bord : j'y raconte toutes les √©tapes qui m√®nent de l'audit des donn√©es jusqu'√† l'entra√Ænement final des mod√®les. L'id√©e est de garder une trace claire de mes choix et de faciliter la relecture pour toute personne qui reprendra le projet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac61e4ff",
   "metadata": {},
   "source": [
    "## 1. Choisir le mode d'ex√©cution\n",
    "\n",
    "Avant de lancer des calculs lourds, je d√©cide si je suis en mode *explicatif* (`train_mode = True`) ou en mode *entra√Ænement complet`. En mode explicatif, je parcours simplement le pipeline pour documenter chaque √©tape sans d√©clencher les boucles de training."
   ]
  },
  {
   "cell_type": "code",
   "id": "6327d30735ab087e",
   "metadata": {},
   "source": [
    "train_mode = True\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices(\"GPU\"))\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "973340e2",
   "metadata": {},
   "source": [
    "Je garde `train_mode` sur `True` pour rester en mode explication : je parcours le pipeline sans lancer de longs entra√Ænements. C'est id√©al pour commenter chaque √©tape calmement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4776a7",
   "metadata": {},
   "source": [
    "## 2. Faire l'inventaire du dossier Cityscapes\n",
    "\n",
    "Je dresse un √©tat des lieux automatique (nombre de fichiers, extensions, sous-dossiers) pour m'assurer que les donn√©es ont bien √©t√© t√©l√©charg√©es et rang√©es."
   ]
  },
  {
   "cell_type": "code",
   "id": "84b61c778fafe1a",
   "metadata": {},
   "source": [
    "# --- Simple dataset scanner (counts only, no filenames, no JSON) ---\n",
    "from pathlib import Path\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "# >>> Change this to your dataset root (WSL path) <<<\n",
    "ROOT = Path(\"../data\")\n",
    "\n",
    "IGNORE_HIDDEN = True       # ignore .git, __pycache__, etc.\n",
    "MAX_DIRS_TO_SHOW = 80      # limit directory lines for readability\n",
    "\n",
    "total_files = 0\n",
    "total_dirs = 0\n",
    "by_ext = Counter()\n",
    "by_dir = {}\n",
    "\n",
    "for dirpath, dirnames, filenames in os.walk(ROOT):\n",
    "    # optionally hide hidden/internal dirs\n",
    "    if IGNORE_HIDDEN:\n",
    "        dirnames[:] = [d for d in dirnames if not d.startswith(\".\") and not d.startswith(\"__\")]\n",
    "    total_dirs += 1\n",
    "    rel = Path(dirpath).relative_to(ROOT) if Path(dirpath) != ROOT else Path(\".\")\n",
    "    by_dir[str(rel)] = len(filenames)\n",
    "    for fn in filenames:\n",
    "        by_ext[Path(fn).suffix.lower()] += 1\n",
    "    total_files += len(filenames)\n",
    "\n",
    "print(f\"[ROOT] {ROOT}\")\n",
    "print(f\"dirs={total_dirs:,}  files={total_files:,}\\n\")\n",
    "\n",
    "print(\"By extension (top 10):\")\n",
    "for ext, n in by_ext.most_common(10):\n",
    "    print(f\"  {ext or '(no ext)'}: {n:,}\")\n",
    "print()\n",
    "\n",
    "print(f\"Directory counts (first {MAX_DIRS_TO_SHOW}):\")\n",
    "for i, (rel, n) in enumerate(sorted(by_dir.items())):\n",
    "    if i >= MAX_DIRS_TO_SHOW:\n",
    "        print(\"  ... (truncated)\")\n",
    "        break\n",
    "    print(f\"  {rel}: {n}\")\n",
    "\n",
    "# -------- Cityscapes mini-summary (counts only) --------\n",
    "def count_pattern(base: Path, split: str, suffix: str) -> int:\n",
    "    split_dir = base / split\n",
    "    total = 0\n",
    "    if split_dir.exists():\n",
    "        for city_dir in split_dir.iterdir():\n",
    "            if city_dir.is_dir():\n",
    "                total += sum(1 for p in city_dir.iterdir()\n",
    "                             if p.is_file() and p.name.endswith(suffix))\n",
    "    return total\n",
    "\n",
    "print(\"\\n[Cityscapes summary]\")\n",
    "for split in (\"train\", \"val\", \"test\"):\n",
    "    gt_base = ROOT / \"gtFine\"\n",
    "    left_base = ROOT / \"leftImg8bit\"\n",
    "    label = count_pattern(gt_base, split, \"_gtFine_labelIds.png\")\n",
    "    color = count_pattern(gt_base, split, \"_gtFine_color.png\")\n",
    "    inst  = count_pattern(gt_base, split, \"_gtFine_instanceIds.png\")\n",
    "    poly  = count_pattern(gt_base, split, \"_gtFine_polygons.json\")\n",
    "    left  = count_pattern(left_base, split, \"_leftImg8bit.png\")\n",
    "    print(f\"  {split:5s}: leftImg8bit={left:6d}  labelIds={label:6d}  color={color:6d}  instanceIds={inst:6d}  polygons.json={poly:6d}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9ec2192e",
   "metadata": {},
   "source": [
    "Je fais tourner un petit script qui compte les fichiers par dossier et par extension. Si une image ou un masque manque, je le vois tout de suite dans le r√©capitulatif."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70308dc3",
   "metadata": {},
   "source": [
    "## 3. V√©rifier l'appairage images / masques\n",
    "\n",
    "Chaque image RGB doit avoir un masque d'annotations qui porte le m√™me identifiant. Je compare les ensembles pour rep√©rer d'√©ventuels manques avant de poursuivre."
   ]
  },
  {
   "cell_type": "code",
   "id": "6b8ee8ae56f5c54f",
   "metadata": {},
   "source": [
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path(\"../data\")  # adapte si besoin\n",
    "SUF_LEFT = \"_leftImg8bit.png\"\n",
    "SUF_LBL  = \"_gtFine_labelIds.png\"\n",
    "\n",
    "def base_id(name: str) -> str:\n",
    "    return name[:-len(SUF_LEFT)] if name.endswith(SUF_LEFT) else name[:-len(SUF_LBL)]\n",
    "\n",
    "def split_counts(split: str):\n",
    "    left_dir = ROOT / \"leftImg8bit\" / split\n",
    "    lbl_dir  = ROOT / \"gtFine\"      / split\n",
    "    left = sorted(left_dir.rglob(f\"*{SUF_LEFT}\")) if left_dir.exists() else []\n",
    "    lbl  = sorted(lbl_dir.rglob (f\"*{SUF_LBL}\" )) if lbl_dir.exists()  else []\n",
    "    left_ids = {base_id(p.name) for p in left}\n",
    "    lbl_ids  = {base_id(p.name) for p in lbl}\n",
    "    paired = left_ids & lbl_ids\n",
    "    print(f\"{split:<5} | left={len(left):4d}  labels={len(lbl):4d}  paired={len(paired):4d}\")\n",
    "\n",
    "for sp in (\"train\", \"val\", \"test\"):\n",
    "    split_counts(sp)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "71ee298b",
   "metadata": {},
   "source": [
    "Je construis deux ensembles de noms (images et masques) et je v√©rifie qu'ils co√Øncident parfaitement. En cas d'√©cart, je saurais qu'il faut r√©g√©n√©rer ou t√©l√©charger les donn√©es manquantes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31fa17c",
   "metadata": {},
   "source": [
    "## 4. Visualiser rapidement quelques exemples\n",
    "\n",
    "Un contr√¥le visuel reste indispensable : je charge une poign√©e d'images et superpose leur masque couleur pour confirmer que les annotations collent bien √† la r√©alit√©."
   ]
  },
  {
   "cell_type": "code",
   "id": "3b30f7c4d8786b68",
   "metadata": {},
   "source": [
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "ROOT = Path(\"../data\")\n",
    "\n",
    "PALETTE = {\n",
    "    7:(128,64,128), 8:(244,35,232), 11:(70,70,70), 12:(102,102,156), 13:(190,153,153),\n",
    "    17:(153,153,153), 19:(250,170,30), 20:(220,220,0), 21:(107,142,35), 22:(152,251,152),\n",
    "    23:(70,130,180), 24:(220,20,60), 25:(255,0,0), 26:(0,0,142), 27:(0,0,70),\n",
    "    28:(0,60,100), 31:(0,80,100), 32:(0,0,230), 33:(119,11,32),\n",
    "}\n",
    "\n",
    "def pairs(split=\"val\"):\n",
    "    lbls = sorted((ROOT/\"gtFine\"/split).rglob(\"*_gtFine_labelIds.png\"))\n",
    "    out = []\n",
    "    for lp in lbls:\n",
    "        stem = lp.name.replace(\"_gtFine_labelIds.png\", \"\")\n",
    "        city = lp.parent.name\n",
    "        left = ROOT/\"leftImg8bit\"/split/city/(stem+\"_leftImg8bit.png\")\n",
    "        if left.exists():\n",
    "            out.append((left, lp))\n",
    "    return out\n",
    "\n",
    "def colorize(ids: np.ndarray) -> Image.Image:\n",
    "    h, w = ids.shape\n",
    "    rgb = np.zeros((h, w, 3), np.uint8)\n",
    "    for k, c in PALETTE.items():\n",
    "        rgb[ids == k] = c\n",
    "    return Image.fromarray(rgb, \"RGB\")\n",
    "\n",
    "def overlay(img: Image.Image, mask_rgb: Image.Image, alpha=0.5) -> Image.Image:\n",
    "    a = np.asarray(img.convert(\"RGB\"), np.float32)\n",
    "    b = np.asarray(mask_rgb, np.float32)\n",
    "    return Image.fromarray(np.clip((1-alpha)*a + alpha*b, 0, 255).astype(np.uint8))\n",
    "\n",
    "samples = pairs(\"val\")\n",
    "assert samples, \"No pairs found ‚Äî check your paths.\"\n",
    "random.shuffle(samples)\n",
    "k = 3\n",
    "\n",
    "plt.figure(figsize=(15, 5*k))\n",
    "for i, (left_p, lbl_p) in enumerate(samples[:k]):\n",
    "    left = Image.open(left_p).convert(\"RGB\")\n",
    "    ids  = np.array(Image.open(lbl_p))\n",
    "    mask = colorize(ids)\n",
    "    over = overlay(left, mask, alpha=0.45)\n",
    "    for j, (img, title) in enumerate([(left,\"leftImg8bit\"),(mask,\"labelIds (colored)\"),(over,\"overlay\")]):\n",
    "        ax = plt.subplot(k, 3, i*3 + j + 1)\n",
    "        ax.imshow(img); ax.set_title(f\"{left_p.parent.name} ‚Äî {title}\", fontsize=10); ax.axis(\"off\")\n",
    "plt.tight_layout(); plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9abf36f1",
   "metadata": {},
   "source": [
    "Je pioche quelques couples image/masque et j'affiche la superposition couleur. C'est un contr√¥le visuel simple mais efficace pour confirmer que le pr√©traitement fonctionne."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1280e711",
   "metadata": {},
   "source": [
    "## 5. Ramener 32 classes Cityscapes vers 8 classes pratiques\n",
    "\n",
    "La version originale de Cityscapes comporte beaucoup de cat√©gories fines. Je compacte ces 32 classes en 8 grandes familles pour acc√©l√©rer l'entra√Ænement tout en conservant le signal principal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f540b1886f92c7b1",
   "metadata": {},
   "source": [
    "\n",
    "### Remapping Cityscapes 32‚Üí8 classes"
   ]
  },
  {
   "cell_type": "code",
   "id": "1b632fc00041fe27",
   "metadata": {},
   "source": [
    "# --- 32‚Üí8 mapping (Cityscapes labelIds -> 8-class IDs), ignore = 255 ---\n",
    "import numpy as np\n",
    "\n",
    "CS_LABELID_TO_8 = {\n",
    "    # 0..5 (voids) -> ignore by LUT fill (no need to list)\n",
    "    6: 0,\n",
    "    7: 0,  9: 0, 10: 0,           # road-like: road, parking, rail track\n",
    "    8: 1,                         # sidewalk\n",
    "    11: 2, 12: 2, 13: 2, 14: 2, 15: 2, 16: 2,   # building + barriers\n",
    "    17: 3, 18: 3, 19: 3, 20: 3,                 # traffic objs (pole/ts/tl)\n",
    "    21: 4, 22: 4,                                 # vegetation + terrain\n",
    "    23: 5,                                       # sky\n",
    "    24: 6, 25: 6,                                 # person + rider\n",
    "    26: 7, 27: 7, 28: 7, 29: 7, 30: 7, 31: 7, 32: 7, 33: 7,  # vehicles\n",
    "}\n",
    "\n",
    "def build_labelid_to8_lut(ignore_value: int = 255) -> np.ndarray:\n",
    "    \"\"\"Create a 256-entry LUT mapping Cityscapes labelIds -> {0..7} or 255(ignore).\"\"\"\n",
    "    lut = np.full(256, ignore_value, dtype=np.uint8)\n",
    "    for k, v in CS_LABELID_TO_8.items():\n",
    "        lut[k] = v\n",
    "    return lut\n",
    "\n",
    "LUT_32TO8 = build_labelid_to8_lut(ignore_value=255)\n",
    "\n",
    "def remap_labelids_to8(arr_uint16: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Vectorized remap of HxW labelIds (uint16/uint8) to 8-class IDs with 255 ignore.\"\"\"\n",
    "    arr = arr_uint16.astype(np.uint16)\n",
    "    arr = np.minimum(arr, 255).astype(np.uint8)\n",
    "    return LUT_32TO8[arr]\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2724760c",
   "metadata": {},
   "source": [
    "Je d√©finis un dictionnaire qui convertit les 32 `labelIds` officiels de Cityscapes en seulement 8 cat√©gories (plus la valeur 255 pour ignorer). Cette r√©duction facilite l'entra√Ænement de mod√®les l√©gers sans perdre l'essentiel."
   ]
  },
  {
   "cell_type": "code",
   "id": "4090ae75134d47fe",
   "metadata": {},
   "source": [
    "PALETTE_8 = {\n",
    "    0:(128,64,128),   # road\n",
    "    1:(244,35,232),   # sidewalk\n",
    "    2:(70,70,70),     # building+barrier\n",
    "    3:(220,220,0),    # traffic objs\n",
    "    4:(107,142,35),   # vegetation/terrain\n",
    "    5:(70,130,180),   # sky\n",
    "    6:(220,20,60),    # person+rider\n",
    "    7:(0,0,142),      # vehicle\n",
    "}\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a912fec5",
   "metadata": {},
   "source": [
    "Pour garder des visualisations lisibles, j'associe chaque identifiant compress√© √† une couleur RGB. Je pourrai ainsi comparer facilement les masques r√©els et ceux pr√©dits."
   ]
  },
  {
   "cell_type": "code",
   "id": "623c52d0928c016c",
   "metadata": {},
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "def colorize_8(label8: np.ndarray, palette: dict) -> Image.Image:\n",
    "    h, w = label8.shape\n",
    "    rgb = np.zeros((h, w, 3), np.uint8)\n",
    "    for k, c in palette.items():\n",
    "        rgb[label8 == k] = c\n",
    "    return Image.fromarray(rgb, \"RGB\")\n",
    "\n",
    "sample_lbl = next(Path(\"../data/gtFine/val/frankfurt\").glob(\"*_gtFine_labelIds.png\"))\n",
    "arr = np.array(Image.open(sample_lbl))\n",
    "arr8 = remap_labelids_to8(arr)\n",
    "plt.figure(figsize=(8,4)); plt.imshow(colorize_8(arr8, PALETTE_8)); plt.axis(\"off\"); plt.title(\"8-class mask\"); plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "50683e6e",
   "metadata": {},
   "source": [
    "Je rassemble deux utilitaires : `colorize_8` pour transformer un masque d'indices en image coloris√©e et `overlay_mask` pour coller ce masque sur l'image d'origine. Je les r√©utiliserai tout au long du carnet pour illustrer les r√©sultats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54219814",
   "metadata": {},
   "source": [
    "Je coupe les logs bavards de TensorFlow, j'autorise la m√©moire GPU √† grandir au fil des besoins et je convertis la table de remapping en tenseur. Je regroupe aussi les fonctions qui listent les fichiers, chargent les images/masques et appliquent les augmentations pour fabriquer des `tf.data.Dataset` efficaces."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80fe41e",
   "metadata": {},
   "source": [
    "## 7. Mesurer l'√©quilibre des classes\n",
    "\n",
    "Avant d'entra√Æner un mod√®le, je veux conna√Ætre le poids de chaque classe : cela influence le choix des m√©triques et des pond√©rations de perte."
   ]
  },
  {
   "cell_type": "code",
   "id": "fa8eafa784ea3287",
   "metadata": {},
   "source": [
    "# ==== Class balance for Cityscapes 8 classes (with ignore=255) ====\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# ---- Config (adapt if needed) ----\n",
    "ROOT = Path(\"../data\")          # dataset root (WSL path)\n",
    "SPLIT = \"train\"                 # \"train\" | \"val\" | \"test\"\n",
    "SUF_LBL = \"_gtFine_labelIds.png\"\n",
    "\n",
    "# 8-class names (your mapping)\n",
    "CLASS8_NAMES = [\n",
    "    \"road\", \"sidewalk\", \"building+barriers\", \"traffic-objs\",\n",
    "    \"vegetation+terrain\", \"sky\", \"person+rider\", \"vehicle\"\n",
    "]\n",
    "\n",
    "# If LUT_32TO8 not in scope, (re)build it quickly:\n",
    "try:\n",
    "    LUT_32TO8\n",
    "except NameError:\n",
    "    CS_LABELID_TO_8 = {\n",
    "        6:0, 7:0, 9:0, 10:0, 8:1, 11:2,12:2,13:2,14:2,15:2,16:2,\n",
    "        17:3,18:3,19:3,20:3, 21:4,22:4, 23:5, 24:6,25:6,\n",
    "        26:7,27:7,28:7,29:7,30:7,31:7,32:7,33:7,\n",
    "    }\n",
    "    LUT_32TO8 = np.full(256, 255, dtype=np.uint8)\n",
    "    for k, v in CS_LABELID_TO_8.items():\n",
    "        LUT_32TO8[k] = v\n",
    "\n",
    "def remap_to8_np(arr_label_ids: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"arr_label_ids: HxW uint16/uint8 -> HxW uint8 in {0..7,255}\"\"\"\n",
    "    arr = arr_label_ids.astype(np.uint16)\n",
    "    arr = np.minimum(arr, 255).astype(np.uint8)\n",
    "    return LUT_32TO8[arr]\n",
    "\n",
    "def class_balance(split: str = SPLIT):\n",
    "    lbl_paths = sorted((ROOT/\"gtFine\"/split).rglob(f\"*{SUF_LBL}\"))\n",
    "    assert lbl_paths, f\"No labels found under {ROOT}/gtFine/{split}\"\n",
    "    counts = np.zeros(8, dtype=np.int64)\n",
    "    ignore = 0\n",
    "    for i, p in enumerate(lbl_paths, 1):\n",
    "        lab = np.array(Image.open(p))         # (H,W) uint16/uint8\n",
    "        lab8 = remap_to8_np(lab)              # (H,W) uint8\n",
    "        m_ignore = (lab8 == 255)\n",
    "        ignore += int(m_ignore.sum())\n",
    "        # bincount only on valid pixels\n",
    "        c = np.bincount(lab8[~m_ignore].ravel(), minlength=8)\n",
    "        counts += c[:8]\n",
    "        if i % 500 == 0 or i == len(lbl_paths):\n",
    "            print(f\"[{split}] processed {i}/{len(lbl_paths)} images...\", end=\"\\r\")\n",
    "    print()\n",
    "    total_valid = int(counts.sum())\n",
    "    total_pixels = total_valid + ignore\n",
    "    freqs = counts / max(total_valid, 1)\n",
    "    return counts, ignore, total_valid, total_pixels, freqs\n",
    "\n",
    "counts, ignore, total_valid, total_pixels, freqs = class_balance(\"train\")\n",
    "\n",
    "print(\"\\n=== Class balance (train) ===\")\n",
    "for k, (name, n, f) in enumerate(zip(CLASS8_NAMES, counts, freqs)):\n",
    "    print(f\"{k}: {name:<20s}  pixels={n:,}   freq={f:.4%}\")\n",
    "print(f\"\\nignore pixels (==255): {ignore:,}\")\n",
    "print(f\"total valid pixels:     {total_valid:,}\")\n",
    "print(f\"total pixels (incl. ignore): {total_pixels:,}\")\n",
    "\n",
    "# ---- Optional: derive class weights ----\n",
    "# Inverse-frequency, normalized to mean=1 (good starting point)\n",
    "weights_inv = (1.0 / np.maximum(freqs, 1e-12))\n",
    "weights_inv = weights_inv / weights_inv.mean()\n",
    "print(\"\\nSuggested class weights (inverse-freq, mean‚âà1):\")\n",
    "for k, (name, w) in enumerate(zip(CLASS8_NAMES, weights_inv)):\n",
    "    print(f\"{k}: {name:<20s}  w={w:.3f}\")\n",
    "\n",
    "# Median-frequency balancing (alternative)\n",
    "median_f = np.median(freqs[freqs > 0])\n",
    "weights_med = median_f / np.maximum(freqs, 1e-12)\n",
    "weights_med = weights_med / weights_med.mean()\n",
    "print(\"\\nSuggested class weights (median-freq, mean‚âà1):\")\n",
    "for k, (name, w) in enumerate(zip(CLASS8_NAMES, weights_med)):\n",
    "    print(f\"{k}: {name:<20s}  w={w:.3f}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "217d1bd6",
   "metadata": {},
   "source": [
    "Je calcule la distribution de pixels par classe sur le split choisi. Ce comptage (apr√®s conversion 32‚Üí8) m'aide √† diagnostiquer les d√©s√©quilibres et √† d√©cider s'il faut appliquer des pond√©rations de perte ou des strat√©gies de sur-√©chantillonnage."
   ]
  },
  {
   "cell_type": "code",
   "id": "e8433da3712483ac",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# expects: counts (np.array shape [8]), freqs (shape [8]), ignore (int),\n",
    "#          total_valid (int), total_pixels (int), CLASS8_NAMES (list of 8 str)\n",
    "\n",
    "# ---- 1) Bar chart des 8 classes (tri√© d√©croissant) ----\n",
    "order = np.argsort(freqs)[::-1]\n",
    "names_sorted = [CLASS8_NAMES[i] for i in order]\n",
    "freqs_sorted = freqs[order]\n",
    "counts_sorted = counts[order]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "bars = plt.bar(range(len(names_sorted)), freqs_sorted)  # no explicit colors\n",
    "plt.xticks(range(len(names_sorted)), names_sorted, rotation=20, ha=\"right\")\n",
    "plt.ylabel(\"Frequency (share of valid pixels)\")\n",
    "plt.title(\"Cityscapes (train) ‚Äî Class balance (8 classes)\")\n",
    "\n",
    "# annotations: % + millions de pixels\n",
    "for i, (b, f, c) in enumerate(zip(bars, freqs_sorted, counts_sorted)):\n",
    "    plt.text(b.get_x() + b.get_width()/2,\n",
    "             b.get_height() + 0.002,\n",
    "             f\"{f*100:.1f}%\\n{c/1e6:.1f}M\",\n",
    "             ha=\"center\", va=\"bottom\", fontsize=9)\n",
    "\n",
    "plt.ylim(0, max(freqs_sorted)*1.15)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ---- 2) Valid vs Ignore (pour info) ----\n",
    "valid_share = total_valid / total_pixels\n",
    "ignore_share = 1.0 - valid_share\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "bars2 = plt.bar([0,1], [valid_share, ignore_share])\n",
    "plt.xticks([0,1], [\"valid\", \"ignore (==255)\"])\n",
    "plt.ylabel(\"Share of total pixels\")\n",
    "plt.title(\"Valid vs Ignore pixels (train)\")\n",
    "\n",
    "for x, v in zip([0,1], [valid_share, ignore_share]):\n",
    "    plt.text(x, v + 0.005, f\"{v*100:.1f}%\", ha=\"center\", va=\"bottom\")\n",
    "\n",
    "plt.ylim(0, 1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "461c6915",
   "metadata": {},
   "source": [
    "√Ä partir des comptages pr√©c√©dents, je trace un histogramme normalis√©, j'affiche les fr√©quences et quelques statistiques globales. C'est une √©tape cl√© pour documenter la difficult√© du jeu de donn√©es et motiver d'√©ventuelles compensations durant l'entra√Ænement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891e99ba",
   "metadata": {},
   "source": [
    "## 8. Instancier les configurations\n",
    "\n",
    "Je mat√©rialise les dataclasses `DataConfig`, `TrainConfig` et `AugmentConfig`. Elles regroupent toutes les options (chemins, tailles d'images, scheduler, callbacks) pour √©viter les copier-coller et garder des exp√©riences tra√ßables."
   ]
  },
  {
   "cell_type": "code",
   "id": "d9d9ad6ec23362d",
   "metadata": {},
   "source": [
    "# In notebook (Python)\n",
    "from scripts.config import DataConfig, TrainConfig, AugmentConfig\n",
    "from scripts.train import train\n",
    "\n",
    "# Configuration rapide pour les exp√©riences contr√¥l√©es\n",
    "data_cfg = DataConfig(\n",
    "    data_root=\"../data\",\n",
    "    height=512,\n",
    "    width=1024,\n",
    "    batch_size=2,\n",
    "    deterministic_input=False,\n",
    "    cache_val=False,\n",
    "    max_train_samples=100,\n",
    "    max_val_samples=100,\n",
    ")\n",
    "\n",
    "# Recette DeepLab optimis√©e pour converger plus vite (<5h)\n",
    "aug_cfg = AugmentConfig(\n",
    "    enabled=True,\n",
    ")\n",
    "\n",
    "train_cfg = TrainConfig(\n",
    "    lr=5e-4,\n",
    "    epochs=80,\n",
    "    optimizer=\"adamw\",\n",
    "    weight_decay=1e-4,\n",
    "    lr_schedule=\"cosine_warmup\",\n",
    "    warmup_epochs=5.0,\n",
    "    min_lr_ratio=0.05,\n",
    "    precision_policy=\"mixed_float16\",\n",
    "    exp_name=\"cityscapes-seg-8cls\",\n",
    ")\n",
    "\n",
    "deeplab_kwargs = {\"aspp_dropout\": 0.5}\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b3b9819cc887027b",
   "metadata": {},
   "source": [
    "## 10. Contr√¥ler visuellement la data augmentation\n",
    "\n",
    "En mode analyse, j'affiche plusieurs couples image/masque avant/apr√®s transformation pour v√©rifier que les augmentations Albumentations respectent bien les contours."
   ]
  },
  {
   "cell_type": "code",
   "id": "fae32854cfcd9ef9",
   "metadata": {},
   "source": [
    "if not train_mode :\n",
    "    import random\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from PIL import Image\n",
    "\n",
    "    from scripts.config import AugmentConfig\n",
    "    from scripts.augment import build_augment_fn\n",
    "    from scripts.remap import build_cityscapes_8cls_lut, remap_labels\n",
    "\n",
    "    lut = build_cityscapes_8cls_lut(data_cfg.ignore_index)\n",
    "    no_aug_fn = build_augment_fn(AugmentConfig(enabled=False), data_cfg.height, data_cfg.width, data_cfg.ignore_index)\n",
    "    augmented_fn = build_augment_fn(aug_cfg, data_cfg.height, data_cfg.width, data_cfg.ignore_index)\n",
    "\n",
    "    def remap_to_training_ids(mask_np):\n",
    "        mask_tf = tf.convert_to_tensor(mask_np, dtype=tf.int32)\n",
    "        return remap_labels(mask_tf, lut).numpy()\n",
    "\n",
    "    def colorize_mask(mask_np, palette=PALETTE_8, ignore_value=data_cfg.ignore_index):\n",
    "        rgb = np.zeros((mask_np.shape[0], mask_np.shape[1], 3), dtype=np.uint8)\n",
    "        for cls_id, color in palette.items():\n",
    "            rgb[mask_np == cls_id] = color\n",
    "        if ignore_value is not None:\n",
    "            rgb[mask_np == ignore_value] = (0, 0, 0)\n",
    "        return rgb\n",
    "\n",
    "    def overlay_mask(image_uint8, mask_uint8, alpha=0.45):\n",
    "        colored = colorize_mask(mask_uint8)\n",
    "        return np.clip((1.0 - alpha) * image_uint8 + alpha * colored, 0, 255).astype(np.uint8)\n",
    "\n",
    "    samples = pairs(\"train\")\n",
    "    assert samples, \"Aucun couple image/masque trouv√© ‚Äî v√©rifie le dossier data.\"\n",
    "\n",
    "    random.shuffle(samples)\n",
    "    num_rows = min(3, len(samples))\n",
    "    fig, axes = plt.subplots(num_rows, 6, figsize=(22, 5 * num_rows))\n",
    "    if num_rows == 1:\n",
    "        axes = np.expand_dims(axes, axis=0)\n",
    "\n",
    "    for row, (left_path, lbl_path) in enumerate(samples[:num_rows]):\n",
    "        raw_img = np.array(Image.open(left_path).convert(\"RGB\"), dtype=np.float32) / 255.0\n",
    "        raw_mask = np.array(Image.open(lbl_path), dtype=np.int32)\n",
    "\n",
    "        mask8 = remap_to_training_ids(raw_mask)\n",
    "\n",
    "        img_tf = tf.convert_to_tensor(raw_img, dtype=tf.float32)\n",
    "        mask_tf = tf.convert_to_tensor(mask8, dtype=tf.int32)\n",
    "\n",
    "        base_img, base_mask = no_aug_fn(img_tf, mask_tf)\n",
    "        aug_img, aug_mask = augmented_fn(img_tf, mask_tf)\n",
    "\n",
    "        base_img_u8 = np.clip(base_img.numpy() * 255.0, 0, 255).astype(np.uint8)\n",
    "        aug_img_u8 = np.clip(aug_img.numpy() * 255.0, 0, 255).astype(np.uint8)\n",
    "        base_mask_u8 = base_mask.numpy().astype(np.uint8)\n",
    "        aug_mask_u8 = aug_mask.numpy().astype(np.uint8)\n",
    "\n",
    "        base_mask_rgb = colorize_mask(base_mask_u8)\n",
    "        aug_mask_rgb = colorize_mask(aug_mask_u8)\n",
    "\n",
    "        axes[row, 0].imshow(base_img_u8)\n",
    "        axes[row, 0].set_title(\"Image (resize)\")\n",
    "        axes[row, 1].imshow(base_mask_rgb)\n",
    "        axes[row, 1].set_title(\"Masque (resize)\")\n",
    "        axes[row, 2].imshow(overlay_mask(base_img_u8, base_mask_u8))\n",
    "        axes[row, 2].set_title(\"Overlay resize\")\n",
    "        axes[row, 3].imshow(aug_img_u8)\n",
    "        axes[row, 3].set_title(\"Image augment√©e\")\n",
    "        axes[row, 4].imshow(aug_mask_rgb)\n",
    "        axes[row, 4].set_title(\"Masque augment√©\")\n",
    "        axes[row, 5].imshow(overlay_mask(aug_img_u8, aug_mask_u8))\n",
    "        axes[row, 5].set_title(\"Overlay augment√©e\")\n",
    "\n",
    "        for ax in axes[row]:\n",
    "            ax.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "96f84853",
   "metadata": {},
   "source": [
    "Quand je suis en mode analyse, j'affiche c√¥te √† c√¥te l'image originale et l'image augment√©e. Cela me permet de valider √† l'≈ìil nu que les transformations (rotations, flips, jitter de couleur) respectent les contours des objets."
   ]
  },
  {
   "cell_type": "code",
   "id": "44c2b5ff61d6ffcf",
   "metadata": {},
   "source": [
    "if not train_mode :\n",
    "    from notebook.scripts.data import build_dataset\n",
    "\n",
    "    val_ds = build_dataset(\n",
    "        data_cfg,\n",
    "        AugmentConfig(enabled=False),\n",
    "        split=\"val\",\n",
    "        training=False,\n",
    "    )\n",
    "\n",
    "    images, masks, _ = next(iter(val_ds))\n",
    "    images_np = images.numpy()\n",
    "    masks_np = masks.numpy()\n",
    "\n",
    "    num_samples = min(3, images_np.shape[0])\n",
    "    plt.figure(figsize=(15, 5 * num_samples))\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        image = images_np[i]\n",
    "        mask = masks_np[i]\n",
    "\n",
    "        if image.dtype != np.uint8:\n",
    "            image_u8 = np.clip(image * 255.0, 0, 255).astype(np.uint8)\n",
    "        else:\n",
    "            image_u8 = image\n",
    "\n",
    "        mask_u8 = mask.astype(np.uint8)\n",
    "        mask_rgb = colorize_mask(mask_u8)\n",
    "        overlay_rgb = overlay_mask(image_u8, mask_u8)\n",
    "\n",
    "        overlay_on_black = overlay_mask(np.zeros_like(image_u8), mask_u8, alpha=1.0)\n",
    "        assert np.array_equal(overlay_on_black, mask_rgb), \"Overlay misaligned with mask (check dataset pipeline).\"\n",
    "\n",
    "        for j, (img, title) in enumerate([\n",
    "            (image_u8, \"Image (val)\"),\n",
    "            (mask_rgb, \"Masque coloris√©\"),\n",
    "            (overlay_rgb, \"Overlay\"),\n",
    "        ]):\n",
    "            ax = plt.subplot(num_samples, 3, i * 3 + j + 1)\n",
    "            ax.imshow(img)\n",
    "            ax.set_title(f\"√âchantillon {i + 1} ‚Äî {title}\")\n",
    "            ax.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7b1c755b",
   "metadata": {},
   "source": [
    "Toujours en mode exploration, je pr√©pare un petit dataset de validation sans augmentation. Il me sert de jeu d'inspection pour v√©rifier plus tard la coh√©rence des pr√©dictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18988ddd",
   "metadata": {},
   "source": [
    "## 11. Pr√©parer les entra√Ænements des diff√©rents mod√®les\n",
    "\n",
    "Je r√©duis les logs TensorFlow, j'initialise la croissance m√©moire GPU puis je duplique la configuration de base pour chaque architecture test√©e."
   ]
  },
  {
   "cell_type": "code",
   "id": "e50c7bd50e46b8ac",
   "metadata": {},
   "source": [
    "import os\n",
    "\n",
    "\n",
    "# ‚Üì‚Üì‚Üì Quieter TensorFlow logs (set BEFORE importing tf)\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"     # 0=all, 1=INFO off, 2=INFO+WARNING off, 3=all off\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\"  # avoid grabbing all GPU memory\n",
    "# Optional: disable oneDNN (removes the \"oneDNN custom ops are on\" line, and tiny numeric diffs)\n",
    "# os.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\"\n",
    "\n",
    "from absl import logging as absl_logging\n",
    "absl_logging.set_verbosity(absl_logging.ERROR)  # reduce absl spam\n",
    "\n",
    "# (Optional) confirm GPU + set memory growth (extra safety)\n",
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "for g in gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(g, True)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "print(\"TF:\", tf.__version__, \"| GPUs:\", gpus)\n",
    "\n",
    "# ==========================\n",
    "# Cityscapes 32‚Üí8 remapping\n",
    "# ==========================\n",
    "import numpy as np\n",
    "\n",
    "# 8 classes for embedded use (ignore=255):\n",
    "# 0=road (7,9,10) | 1=sidewalk(8) | 2=building+barriers(11‚Äì16) | 3=traffic objs(17‚Äì20)\n",
    "# 4=vegetation+terrain(21,22) | 5=sky(23) | 6=person+rider(24,25) | 7=vehicle(26‚Äì33)\n",
    "CS_LABELID_TO_8 = {\n",
    "    6:0,\n",
    "    7:0, 9:0, 10:0,\n",
    "    8:1,\n",
    "    11:2, 12:2, 13:2, 14:2, 15:2, 16:2,\n",
    "    17:3, 18:3, 19:3, 20:3,\n",
    "    21:4, 22:4,\n",
    "    23:5,\n",
    "    24:6, 25:6,\n",
    "    26:7, 27:7, 28:7, 29:7, 30:7, 31:7, 32:7, 33:7,\n",
    "}\n",
    "\n",
    "def build_labelid_to8_lut(ignore_value: int = 255) -> np.ndarray:\n",
    "    lut = np.full(256, ignore_value, dtype=np.uint8)\n",
    "    for k, v in CS_LABELID_TO_8.items():\n",
    "        lut[k] = v\n",
    "    return lut\n",
    "\n",
    "LUT_32TO8 = build_labelid_to8_lut(ignore_value=255)\n",
    "LUT_TF = tf.convert_to_tensor(LUT_32TO8, dtype=tf.uint8)  # shape [256]\n",
    "\n",
    "# ===================\n",
    "# Dataset (tf.data)\n",
    "# ===================\n",
    "from pathlib import Path\n",
    "ROOT = Path(\"../data\")               # <<< change if needed (WSL path)\n",
    "INPUT_SIZE = (512, 1024)             # (H, W)\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "SUF_LEFT = \"_leftImg8bit.png\"\n",
    "SUF_LBL  = \"_gtFine_labelIds.png\"\n",
    "\n",
    "def list_pairs(split: str):\n",
    "    \"\"\"Return two aligned lists: left paths and label paths for a given split.\"\"\"\n",
    "    lefts, labels = [], []\n",
    "    lbl_root = ROOT / \"gtFine\" / split\n",
    "    for lbl in sorted(lbl_root.rglob(f\"*{SUF_LBL}\")):\n",
    "        city = lbl.parent.name\n",
    "        stem = lbl.name.replace(SUF_LBL, \"\")\n",
    "        left = ROOT / \"leftImg8bit\" / split / city / f\"{stem}{SUF_LEFT}\"\n",
    "        if left.exists():\n",
    "            lefts.append(str(left))\n",
    "            labels.append(str(lbl))\n",
    "    if not lefts:\n",
    "        raise FileNotFoundError(f\"No pairs found for split='{split}'. Check your paths under {ROOT}.\")\n",
    "    return lefts, labels\n",
    "\n",
    "def decode_and_preprocess(left_path, lbl_path, training: bool):\n",
    "    # 1) Read bytes\n",
    "    left_bytes = tf.io.read_file(left_path)\n",
    "    lbl_bytes  = tf.io.read_file(lbl_path)\n",
    "\n",
    "    # 2) Decode\n",
    "    img = tf.io.decode_png(left_bytes, channels=3)     # uint8 [H,W,3]\n",
    "    lab = tf.io.decode_png(lbl_bytes,  channels=1)     # uint8/16 [H,W,1]\n",
    "\n",
    "    # 3) To workable dtypes\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)   # [0,1]\n",
    "    lab = tf.cast(lab, tf.int32)                          # index dtype for LUT\n",
    "\n",
    "    # 4) Remap 32‚Üí8 via LUT\n",
    "    lab_clipped = tf.minimum(lab, 255)\n",
    "    lab8 = tf.gather(LUT_TF, lab_clipped)                 # uint8 [H,W,1]\n",
    "    lab8 = tf.squeeze(lab8, axis=-1)                      # uint8 [H,W]\n",
    "\n",
    "    # 5) Simple augment (sync flip)\n",
    "    if training:\n",
    "        do_flip = tf.random.uniform(()) > 0.5\n",
    "        img  = tf.cond(do_flip, lambda: tf.image.flip_left_right(img), lambda: img)\n",
    "        lab8 = tf.cond(do_flip, lambda: tf.image.flip_left_right(lab8[..., None])[:, :, 0], lambda: lab8)\n",
    "\n",
    "    # 6) Resize (labels in nearest, keep uint8)\n",
    "    img  = tf.image.resize(img,  INPUT_SIZE, method=\"bilinear\")\n",
    "    lab8 = tf.cast(tf.image.resize(lab8[..., None], INPUT_SIZE, method=\"nearest\")[:, :, 0], tf.uint8)\n",
    "\n",
    "    # 7) Ignore handling ‚Üí sample_weight (float32); labels safe (uint8‚Üíint32)\n",
    "    ignore_val = tf.constant(255, dtype=tf.uint8)\n",
    "    ignore = tf.equal(lab8, ignore_val)  # bool [H,W]\n",
    "\n",
    "    weights = tf.where(ignore,\n",
    "                       tf.zeros_like(lab8, dtype=tf.float32),\n",
    "                       tf.ones_like(lab8,  dtype=tf.float32))              # float32 [H,W]\n",
    "\n",
    "    lab8_safe = tf.where(ignore,\n",
    "                         tf.zeros_like(lab8),   # uint8 0 (will be masked by weights anyway)\n",
    "                         lab8)\n",
    "    labels = tf.cast(lab8_safe, tf.int32)                                    # int32 [H,W]\n",
    "\n",
    "    return img, labels, weights\n",
    "\n",
    "def make_dataset(split: str, batch_size: int = BATCH_SIZE, training: bool = True) -> tf.data.Dataset:\n",
    "    lefts, labels = list_pairs(split)\n",
    "    ds = tf.data.Dataset.from_tensor_slices((lefts, labels))\n",
    "    if training:\n",
    "        ds = ds.shuffle(buffer_size=min(len(lefts), 2000), reshuffle_each_iteration=True)\n",
    "    ds = ds.map(lambda l, y: decode_and_preprocess(l, y, training),\n",
    "                num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds = ds.batch(batch_size, drop_remainder=training)\n",
    "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "# ==============\n",
    "# Smoke test\n",
    "# ==============\n",
    "train_ds = make_dataset(\"train\", batch_size=2, training=True)\n",
    "xb, yb, wb = next(iter(train_ds))\n",
    "print(\"x:\", xb.shape, xb.dtype, \"| y:\", yb.shape, yb.dtype, \"| w:\", wb.shape, wb.dtype)\n",
    "\n",
    "# Example compile/fit (model must output logits with 8 channels)\n",
    "# loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "# opt  = tf.keras.optimizers.Adam(1e-3)\n",
    "# model.compile(optimizer=opt, loss=loss, metrics=[\"accuracy\"])\n",
    "# model.fit(train_ds,\n",
    "#           validation_data=make_dataset(\"val\", batch_size=2, training=False),\n",
    "#           epochs=1)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b54c83afdf449ad0",
   "metadata": {},
   "source": [
    "### UNet Mini ‚Äî Baseline rapide"
   ]
  },
  {
   "cell_type": "code",
   "id": "f08d845ee14a58e2",
   "metadata": {},
   "source": [
    "if not train_mode :\n",
    "    from dataclasses import replace\n",
    "    unet_mini_cfg = replace(\n",
    "        train_cfg,\n",
    "        output_dir=\"artifacts/unet_mini\",\n",
    "    )\n",
    "    train(\"unet_mini\", data_cfg, unet_mini_cfg, aug_cfg)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "da988384",
   "metadata": {},
   "source": [
    "Je duplique la configuration de base pour lancer un entra√Ænement U-Net Mini. C'est mon mod√®le le plus l√©ger : parfait pour valider rapidement que tout le pipeline fonctionne."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625be39c1c74f8c2",
   "metadata": {},
   "source": [
    "### UNet VGG16 ‚Äî Version plus profonde"
   ]
  },
  {
   "cell_type": "code",
   "id": "968a91d468deb367",
   "metadata": {},
   "source": [
    " if not train_mode :\n",
    "    unet_vgg16_cfg = replace(\n",
    "        train_cfg,\n",
    "        output_dir=\"artifacts/unet_vgg16\",\n",
    "    )\n",
    "    train(\"unet_vgg16\", data_cfg, unet_vgg16_cfg, aug_cfg)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c7c1b78b",
   "metadata": {},
   "source": [
    "M√™me principe pour U-Net VGG16, plus profond : je change uniquement le nom de sortie pour isoler ses artefacts et comparer ses performances √† part."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97eac04f2c1a0511",
   "metadata": {},
   "source": [
    "### MobileDet Seg ‚Äî Variante compacte"
   ]
  },
  {
   "cell_type": "code",
   "id": "17cc0800dcd2447b",
   "metadata": {},
   "source": [
    " if not train_mode :\n",
    "    mobiledet_seg_cfg = replace(\n",
    "        train_cfg,\n",
    "        output_dir=\"artifacts/mobiledet_seg\",\n",
    "    )\n",
    "    train(\"mobiledet_seg\", data_cfg, mobiledet_seg_cfg, aug_cfg)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a8b21ded",
   "metadata": {},
   "source": [
    "Pour MobileDet-Seg, je garde la m√™me fonction `train` mais je cible un dossier d√©di√©. L'objectif est d'√©valuer une architecture optimis√©e pour les appareils embarqu√©s."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda9ed5cbc57b167",
   "metadata": {},
   "source": [
    "### YOLOv9 Seg ‚Äî Approche one-stage"
   ]
  },
  {
   "cell_type": "code",
   "id": "2bfc844613848b5f",
   "metadata": {},
   "source": [
    " if not train_mode :\n",
    "    yolov9_seg_cfg = replace(\n",
    "        train_cfg,\n",
    "        output_dir=\"artifacts/yolov9_seg\",\n",
    "    )\n",
    "    train(\"yolov9_seg\", data_cfg, yolov9_seg_cfg, aug_cfg)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0cbf5690",
   "metadata": {},
   "source": [
    "YOLOv9-Seg suit exactement la m√™me recette : je param√®tre un r√©pertoire de sortie s√©par√© afin de garder les r√©sultats bien rang√©s et comparables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73d2a8040472e9b",
   "metadata": {},
   "source": [
    "### DeepLabV3+ ResNet50 ‚Äî Mod√®le de r√©f√©rence"
   ]
  },
  {
   "cell_type": "code",
   "id": "c919827d0f66cddd",
   "metadata": {},
   "source": [
    "if not train_mode :\n",
    "    train(\"deeplab_resnet50\", data_cfg, train_cfg, aug_cfg, model_kwargs=deeplab_kwargs)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "33fca599",
   "metadata": {},
   "source": [
    "DeepLabV3+ (ResNet50) joue ici le r√¥le de mod√®le de r√©f√©rence : je le lance seulement en mode entra√Ænement complet afin de mesurer le meilleur niveau atteignable sur ce pipeline r√©duit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154c65411f171045",
   "metadata": {},
   "source": [
    "## 12. Faire le point sur les r√©sultats interm√©diaires\n",
    "\n",
    "Je regroupe ici toutes les m√©triques obtenues lors des entra√Ænements exploratoires. Cela permet de comparer d'un coup d'≈ìil le temps d'entra√Ænement et la qualit√© de segmentation de chaque architecture.\n",
    "\n",
    "| Mod√®le                     |   Dur√©e  | `masked_mIoU` (train) | `val_masked_mIoU` | `pix_acc` | `val_pix_acc` | `dice_coef` | `val_dice_coef` |\n",
    "| :------------------------- | :------: | :-------------------: | :---------------: | :-------: | :-----------: | :---------: | :-------------: |\n",
    "| **DeepLabV3+ (ResNet50)**  | 13.4 min |       **0.947**       |     **0.639**     | **0.989** |   **0.872**   |  **0.965**  |    **0.716**    |\n",
    "| **YOLOv9_seg (simplifi√©)** | 10.5 min |         0.689         |       0.400       |   0.913   |     0.714     |    0.753    |      0.494      |\n",
    "| **MobileDet_seg**          | 16.3 min |         0.938         |       0.502       |   0.987   |     0.779     |    0.953    |      0.600      |\n",
    "| **U-Net VGG16**            | 29.7 min |         0.903         |       0.542       |   0.977   |     0.805     |    0.923    |      0.633      |\n",
    "| **U-Net mini**             |  6.1 min |         0.563         |       0.319       |   0.851   |     0.634     |    0.650    |      0.407      |\n",
    "\n",
    "---\n",
    "\n",
    "## üîç Interpr√©tation m√©trique par m√©trique\n",
    "\n",
    "### üü¶ `masked_mIoU` (train)\n",
    "\n",
    "* Mesure principale de segmentation (intersection sur union moyenne).\n",
    "* Tous sauf U-Net mini > 0.9 en entra√Ænement ‚Üí bon apprentissage.\n",
    "* U-Net mini (0.56) : trop l√©ger, manque de capacit√©.\n",
    "\n",
    "### üüß `val_masked_mIoU`\n",
    "\n",
    "* √âvalue la **g√©n√©ralisation**.\n",
    "* DeepLab (0.639) est **nettement sup√©rieur** aux autres.\n",
    "* U-Net VGG16 (0.54) et MobileDet (0.50) suivent derri√®re.\n",
    "* YOLOv9 seg (0.40) et U-Net mini (0.32) d√©crochent clairement.\n",
    "\n",
    "### üü© `val_pix_acc`\n",
    "\n",
    "* Corr√©lation assez bonne avec `val_mIoU`.\n",
    "* DeepLab atteint 0.87 ‚Üí tr√®s bonne segmentation globale.\n",
    "* U-Net VGG16 ‚âà 0.80 ‚Üí correct.\n",
    "* Les autres chutent < 0.78.\n",
    "\n",
    "### üü™ `val_dice_coef`\n",
    "\n",
    "* Tr√®s proche du mIoU mais plus sensible aux petits objets.\n",
    "* DeepLab ‚âà 0.72 ‚Üí coh√©rent avec sa bonne mIoU.\n",
    "* U-Net VGG16 ‚âà 0.63 et MobileDet ‚âà 0.60 ‚Üí acceptables.\n",
    "* YOLOv9 ‚âà 0.49, U-Net mini ‚âà 0.40 ‚Üí faibles.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öñÔ∏è Analyse comparative\n",
    "\n",
    "| Crit√®re                               | Meilleur mod√®le                            |\n",
    "| :------------------------------------ | :----------------------------------------- |\n",
    "| **Pr√©cision globale (mIoU/Dice)**     | üü¢ **DeepLabV3+ ResNet50**                 |\n",
    "| **G√©n√©ralisation / stabilit√© val**    | üü¢ **DeepLabV3+ ResNet50**                 |\n",
    "| **Compromis vitesse/qualit√©**         | üü¢ **MobileDet_seg** (plus l√©ger, correct) |\n",
    "| **Performance brute (haute qualit√©)** | üü¢ **U-Net VGG16** si VRAM suffisante      |\n",
    "| **L√©geret√© / prototypage rapide**     | üü¢ **U-Net mini**, mais pr√©cision faible   |\n",
    "\n",
    "---\n",
    "\n",
    "## Interpr√©tation d√©taill√©e\n",
    "\n",
    "### ü•á **DeepLabV3+ (ResNet50)**\n",
    "\n",
    "* **Meilleur √©quilibre** entre pr√©cision et stabilit√©.\n",
    "* mIoU = 0.64 (val) et Dice = 0.72 (val) : excellents scores sur 8 classes.\n",
    "* Surapprentissage mod√©r√© (train-val gap raisonnable).\n",
    "* Tr√®s bonne capacit√© √† capter les contours fins et la hi√©rarchie spatiale.\n",
    "  ‚úÖ **‚Üí Mod√®le √† garder comme r√©f√©rence.**\n",
    "\n",
    "### ü•à **U-Net VGG16**\n",
    "\n",
    "* Tr√®s bon entra√Ænement, mais √©cart train-val > 0.35 : l√©ger overfit.\n",
    "* Lourdeur m√©moire (VGG16) mais r√©sultats solides.\n",
    "  ‚úÖ Alternative si tu veux plus de stabilit√© visuelle (textures fines).\n",
    "\n",
    "### ü•â **MobileDet_seg**\n",
    "\n",
    "* Performances correctes pour un mod√®le ‚Äúmobile-like‚Äù.\n",
    "* Bonne efficacit√© (seulement 16 min d‚Äôentra√Ænement, r√©sultats d√©cents).\n",
    "  üü° Bon compromis si tu cibles l‚Äôinf√©rence embarqu√©e.\n",
    "\n",
    "### ‚öôÔ∏è **YOLOv9_seg**\n",
    "\n",
    "* Correct mais sous-optimal : architecture pas parfaitement adapt√©e √† la segmentation dense.\n",
    "* Val mIoU = 0.40, Dice = 0.49 : pas suffisant pour une segmentation de qualit√©.\n",
    "  üî¥ √Ä √©viter pour cette t√¢che sp√©cifique.\n",
    "\n",
    "### ‚ö™ **U-Net mini**\n",
    "\n",
    "* Tr√®s rapide mais sous-entra√Æn√© / sous-dimensionn√©.\n",
    "* Mauvais scores val (mIoU = 0.32, Dice = 0.40).\n",
    "  üî¥ Bon pour tests rapides, pas pour production.\n",
    "\n",
    "---\n",
    "\n",
    "## üßæ Conclusion\n",
    "\n",
    "| Rang | Mod√®le                    | Pourquoi                                                  |\n",
    "| :--: | :------------------------ | :-------------------------------------------------------- |\n",
    "|  ü•á  | **DeepLabV3+ (ResNet50)** | Meilleur √©quilibre pr√©cision / g√©n√©ralisation / stabilit√© |\n",
    "|  ü•à  | **U-Net VGG16**           | Tr√®s bon mais plus lourd, tendance √† overfitter           |\n",
    "|  ü•â  | **MobileDet_seg**         | L√©g√®ret√© et vitesse, mais pr√©cision un cran en dessous    |\n",
    "|   4  | **YOLOv9_seg**            | Pas adapt√© √† la segmentation dense                        |\n",
    "|   5  | **U-Net mini**            | Trop limit√©, r√©sultats faibles                            |\n",
    "\n",
    "---\n",
    "\n",
    "### üîß En r√©sum√©\n",
    "\n",
    "> **DeepLabV3+ ResNet50** est le **meilleur mod√®le global** :\n",
    ">\n",
    "> * meilleures m√©triques de validation,\n",
    "> * bon Dice et mIoU,\n",
    "> * rapport vitesse/qualit√© tr√®s favorable,\n",
    "> * faible overfit compar√© √† VGG16.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f224bfb380ca5bf",
   "metadata": {},
   "source": [
    "## 13. Chercher les hyperparam√®tres avec Optuna\n",
    "\n",
    "Cette cellule encapsule une recherche Optuna (d√©sactiv√©e par d√©faut) pour ajuster automatiquement les hyperparam√®tres de DeepLabV3+. Je la garde comme r√©f√©rence lorsque j'ai le temps de lancer une exploration compl√®te."
   ]
  },
  {
   "cell_type": "code",
   "id": "f1b2aaea",
   "metadata": {},
   "source": [
    "if False:\n",
    "    # === Optuna hyperparameter search for DeepLabV3+ (ResNet50) ===\n",
    "    import json\n",
    "    import gc\n",
    "    from dataclasses import replace\n",
    "\n",
    "    from optuna.exceptions import TrialPruned\n",
    "    try:\n",
    "        import optuna\n",
    "    except ModuleNotFoundError:  # pragma: no cover - handled at runtime\n",
    "        import subprocess, sys\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'optuna', '--quiet'])\n",
    "        import optuna\n",
    "\n",
    "    optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "    physical_gpus = tf.config.list_physical_devices('GPU')\n",
    "    for _gpu in physical_gpus:\n",
    "        try:\n",
    "            tf.config.experimental.set_memory_growth(_gpu, True)\n",
    "        except (RuntimeError, ValueError):\n",
    "            pass\n",
    "\n",
    "\n",
    "    search_data_cfg = replace(\n",
    "        data_cfg,\n",
    "        batch_size=2,\n",
    "        max_train_samples=50,\n",
    "        verbose=False,\n",
    "        max_val_samples=10,\n",
    "    )\n",
    "    search_train_cfg = replace(\n",
    "        train_cfg,\n",
    "        epochs=12,\n",
    "        early_stop_patience=3,\n",
    "        output_dir='artifacts/deeplab_resnet50_optuna',\n",
    "        exp_name='deeplabv3plus-resnet50-optuna',\n",
    "        arch='deeplab_resnet50',\n",
    "    )\n",
    "\n",
    "    _MODEL_PARAM_KEYS = {\n",
    "        'output_stride',\n",
    "        'aspp_dilations',\n",
    "        'decoder_filters',\n",
    "        'aspp_dropout',\n",
    "        'decoder_activation',\n",
    "        'aspp_activation',\n",
    "    }\n",
    "\n",
    "    best_deeplab_model_params = None\n",
    "    best_deeplab_train_params = None\n",
    "    best_deeplab_data_params = None\n",
    "    best_deeplab_val_miou = None\n",
    "\n",
    "\n",
    "    def _suggest_params(trial: optuna.Trial) -> dict:\n",
    "        return {\n",
    "            'output_stride': trial.suggest_categorical('output_stride', [8, 16]),\n",
    "            'aspp_dilations': trial.suggest_categorical('aspp_dilations', [(6, 12, 18), (12, 24, 36)]),\n",
    "            'decoder_filters': trial.suggest_categorical('decoder_filters', [128, 256, 512]),\n",
    "            'aspp_dropout': trial.suggest_float('aspp_dropout', 0.0, 0.3),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True),\n",
    "            'momentum': trial.suggest_float('momentum', 0.8, 0.95),\n",
    "            'weight_decay': trial.suggest_float('weight_decay', 1e-6, 1e-3, log=True),\n",
    "            'optimizer': trial.suggest_categorical('optimizer', ['SGD', 'AdamW']),\n",
    "            'poly_power': trial.suggest_float('poly_power', 0.8, 1.0),\n",
    "            'decoder_activation': trial.suggest_categorical('decoder_activation', ['relu', 'gelu']),\n",
    "            'aspp_activation': trial.suggest_categorical('aspp_activation', ['relu', 'gelu']),\n",
    "        }\n",
    "\n",
    "\n",
    "    def objective(trial: optuna.Trial) -> float:\n",
    "        params = _suggest_params(trial)\n",
    "        tf.keras.backend.clear_session()\n",
    "        gc.collect()\n",
    "\n",
    "        trial_data_cfg = replace(\n",
    "            search_data_cfg,\n",
    "            batch_size=2,\n",
    "        )\n",
    "        momentum = params['momentum'] if params['optimizer'] == 'SGD' else None\n",
    "        trial_train_cfg = replace(\n",
    "            search_train_cfg,\n",
    "            lr=params['learning_rate'],\n",
    "            optimizer=params['optimizer'].lower(),\n",
    "            momentum=momentum,\n",
    "            weight_decay=params['weight_decay'],\n",
    "            poly_power=params['poly_power'],\n",
    "            output_dir=f\"artifacts/deeplab_resnet50_optuna/trial_{trial.number}\",\n",
    "        )\n",
    "        model_kwargs = {k: params[k] for k in _MODEL_PARAM_KEYS}\n",
    "\n",
    "        metrics = {}\n",
    "        try:\n",
    "            metrics = train(\n",
    "                'deeplab_resnet50',\n",
    "                trial_data_cfg,\n",
    "                trial_train_cfg,\n",
    "                aug_cfg,\n",
    "                model_kwargs=model_kwargs,\n",
    "                use_mlflow=False,\n",
    "                keep_artifacts=False,\n",
    "                cleanup_after=True,\n",
    "                probe_dataset=False,\n",
    "            )\n",
    "        except (tf.errors.ResourceExhaustedError, tf.errors.InternalError, MemoryError) as exc:\n",
    "            trial.set_user_attr('failure', f'{type(exc).__name__}: {exc}')\n",
    "            raise TrialPruned(f'Pruned because of resource exhaustion: {exc}') from exc\n",
    "        finally:\n",
    "            del trial_data_cfg, trial_train_cfg, model_kwargs\n",
    "            tf.keras.backend.clear_session()\n",
    "            gc.collect()\n",
    "\n",
    "        val_miou = float(metrics.get('masked_mIoU', 0.0))\n",
    "        trial.set_user_attr('metrics', dict(metrics))\n",
    "        metrics.clear()\n",
    "        metrics = None\n",
    "        return val_miou\n",
    "\n",
    "    def _json_default(value):\n",
    "        if isinstance(value, tuple):\n",
    "            return list(value)\n",
    "        return value\n",
    "\n",
    "\n",
    "    if train_mode:\n",
    "        study = optuna.create_study(direction='maximize', study_name='deeplabv3plus_cityscapes')\n",
    "        study.optimize(objective, n_trials=20, show_progress_bar=False)\n",
    "\n",
    "        best_deeplab_val_miou = float(study.best_value)\n",
    "        best_params = study.best_trial.params\n",
    "        best_deeplab_model_params = {k: best_params[k] for k in _MODEL_PARAM_KEYS}\n",
    "        best_deeplab_train_params = {\n",
    "            'learning_rate': best_params['learning_rate'],\n",
    "            'optimizer': best_params['optimizer'].lower(),\n",
    "            'momentum': best_params['momentum'] if best_params['optimizer'] == 'SGD' else None,\n",
    "            'weight_decay': best_params['weight_decay'],\n",
    "            'poly_power': best_params['poly_power'],\n",
    "        }\n",
    "        best_deeplab_data_params = {'batch_size': best_params['batch_size']}\n",
    "\n",
    "        print(f\"Best val_mIoU: {best_deeplab_val_miou:.4f}\")\n",
    "        print('Best hyperparameters:')\n",
    "        print(json.dumps(best_params, indent=2, default=_json_default))\n",
    "    else:\n",
    "        print('train_mode=False ‚Üí Optuna search skipped.')\n",
    "        best_deeplab_model_params = {}\n",
    "        best_deeplab_train_params = {}\n",
    "        best_deeplab_data_params = {}\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "75116b2e",
   "metadata": {},
   "source": [
    "## 14. Entra√Æner DeepLabV3+ sur 100% des donn√©es\n",
    "\n",
    "Je relance DeepLabV3+ avec **l'int√©gralit√©** du dataset et sansn puis avec toutes les augmentations activ√©es. Gr√¢ce aux dataclasses, un simple `replace` suffit pour figer une nouvelle configuration tra√ßable."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Sans augmentation",
   "id": "baf48f05d43c8931"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if True:\n",
    "    # Baseline sans augmentation : m√©triques logg√©es dans MLflow uniquement\n",
    "    from dataclasses import replace\n",
    "\n",
    "    baseline_data_cfg = replace(\n",
    "        data_cfg,\n",
    "        max_train_samples=None,\n",
    "        max_val_samples=None,\n",
    "    )\n",
    "\n",
    "    baseline_train_cfg = replace(\n",
    "        train_cfg,\n",
    "        output_dir=\"artifacts/deeplab_resnet50_noaug\",\n",
    "        exp_name=\"cityscapes-seg-8cls-noaug\",\n",
    "    )\n",
    "\n",
    "    baseline_aug_cfg = replace(\n",
    "        aug_cfg,\n",
    "        enabled=False,\n",
    "    )\n",
    "\n",
    "    train(\n",
    "        \"deeplab_resnet50\",\n",
    "        baseline_data_cfg,\n",
    "        baseline_train_cfg,\n",
    "        baseline_aug_cfg,\n",
    "        model_kwargs=deeplab_kwargs,\n",
    "        keep_artifacts=True,\n",
    "        cleanup_after=True,\n",
    "    )\n"
   ],
   "id": "c7128a84d3fdf135",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Avec augmentation (final)",
   "id": "58081a698597de53"
  },
  {
   "cell_type": "code",
   "id": "1828657bb72691a6",
   "metadata": {},
   "source": [
    "from dataclasses import replace\n",
    "# Configuration finale : dataset complet + sorties d√©di√©es (avec et sans augmentation)\n",
    "final_data_cfg = replace(\n",
    "    data_cfg,\n",
    "    max_train_samples=None,\n",
    "    max_val_samples=None,\n",
    ")\n",
    "final_train_cfg = replace(\n",
    "    train_cfg,\n",
    "    output_dir=\"artifacts/deeplab_resnet50_full\",\n",
    "    exp_name=\"cityscapes-seg-8cls-full\",\n",
    ")\n",
    "final_aug_cfg = replace(\n",
    "    aug_cfg,\n",
    "    enabled=True,\n",
    ")\n",
    "\n",
    "# Lancement de l'entra√Ænement complet (sauvegarde locale + tracking MLflow)\n",
    "train(\"deeplab_resnet50\", final_data_cfg, final_train_cfg, final_aug_cfg, model_kwargs=deeplab_kwargs)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "dbd9095f",
   "metadata": {},
   "source": [
    "## 15. Sauvegarder le meilleur mod√®le pour l'API\n",
    "\n",
    "Une fois l'apprentissage termin√©, je copie le meilleur checkpoint vers un dossier standardis√© (`artifacts/api`). Cette √©tape garantit que l'API et les futurs tests chargeront exactement le m√™me mod√®le."
   ]
  },
  {
   "cell_type": "code",
   "id": "73c6a586d43eb52b",
   "metadata": {},
   "source": [
    "# Copie explicite du meilleur mod√®le pour l'API\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "best_model = Path(\"artifacts/deeplab_resnet50_full/deeplab_resnet50_best.keras\")\n",
    "api_export = Path(\"artifacts/api/deeplabv3plus_resnet50_full.keras\")\n",
    "api_export.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if best_model.exists():\n",
    "    shutil.copy2(best_model, api_export)\n",
    "    print(f\"‚úÖ Mod√®le API (best) : {api_export}\")\n",
    "else:\n",
    "    raise FileNotFoundError(\"Aucun mod√®le entra√Æn√© trouv√©. Lance d'abord la cellule d'entra√Ænement.\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
